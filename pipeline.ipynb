{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKMsShIPx3J+WdipNy+Bce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsu1214/class2022spring/blob/main/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline  \n",
        "파이프라인은 함수인데 앞부분과 뒷부분만 알고 중간부분은 몰라도 된다는 의미이다. inference는 모델을 만들어놓고 어떤 입력을 주면 결과가 나오는 즉 쓰는 과정을 inference라고 한다. inference를 쉽게 하는 것을 pipeline이라고 한다.  \n",
        "huggingface가면 다 만들어져있다."
      ],
      "metadata": {
        "id": "XwbTwXXIvKSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "DFmEsnAxv2Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"audio-classification\")"
      ],
      "metadata": {
        "id": "t5hbxkO4v4oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래 뒤에 모델을 적어야하지만 만약 적지 않을 경우 default되어 있는 model하나를 가져온다. model = superb/wav2vec2-base-superb-ks  \n",
        "쓰는 방법은 pipe(\"wav파일\") 하면 이게 무슨 단어인지 단어마다 확률을 보여주는 model이다.  \n",
        "녹음파일은 kaggle이라는 사이트에서 유용하게 쓸 수 있는 음성파일들을 공유하고 있다."
      ],
      "metadata": {
        "id": "xkxA8AAFwTIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"automatic-speech-recognition\")"
      ],
      "metadata": {
        "id": "MtGAXJSs0fRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "음성 인식 넣으면 소리를 텍스트로 표현해준다."
      ],
      "metadata": {
        "id": "wWmjx7PX0vu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"conversational\")"
      ],
      "metadata": {
        "id": "96ZBNfJt01Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 함수는 쓰는 방법이 난해하기 때문에 사용방법을 적어두었다.  \n",
        "conversation을 받아온다. 그리고 conversation1,2 해서 각각에 문장을 넣는다. 그리고 마지막에 이 두개를 list로 해서 pipe하면 된다.  \n",
        "그러면 conversation이 내가 한 질문이고 ai가 내 질문에 맞게 대답을 해주고 있다.  \n",
        "그러면 우리가 ai의 답변에 대해 추가 질문을 할 수 있다."
      ],
      "metadata": {
        "id": "jYPwrrna1AYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Conversation\n",
        "\n",
        "conversation_1 = Conversation(\"Going to the movies tonight - any suggestions?\")\n",
        "conversation_2 = Conversation(\"What's the last book you have read?\")\n",
        "pipe([conversation_1, conversation_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58MBnH3I1Ika",
        "outputId": "6f9d7288-bd32-491b-e730-a0891591139a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conversation id: bc0a75be-0ba2-4b5f-afe0-ad92683cd08f \n",
              " user >> Going to the movies tonight - any suggestions? \n",
              " bot >> The Big Lebowski ,\n",
              " Conversation id: 61d814f4-927f-4633-80a3-199eec0d9840 \n",
              " user >> What's the last book you have read? \n",
              " bot >> The Last Question ]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래가 ai답변에 대해 추가질문을 하는 방법이다."
      ],
      "metadata": {
        "id": "VxPVrqe010KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_1.add_user_input(\"Is it an action movie?\")\n",
        "conversation_2.add_user_input(\"What is the genre of this book?\")\n",
        "pipe([conversation_1, conversation_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQrtyWEb1yAs",
        "outputId": "c875a4e5-e3ae-458b-8fba-57aeecb3f53b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conversation id: bc0a75be-0ba2-4b5f-afe0-ad92683cd08f \n",
              " user >> Going to the movies tonight - any suggestions? \n",
              " bot >> The Big Lebowski \n",
              " user >> Is it an action movie? \n",
              " bot >> It's a comedy. , Conversation id: 61d814f4-927f-4633-80a3-199eec0d9840 \n",
              " user >> What's the last book you have read? \n",
              " bot >> The Last Question \n",
              " user >> What is the genre of this book? \n",
              " bot >> I'm not sure, but I think it's fantasy. ]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"feature-extraction\")"
      ],
      "metadata": {
        "id": "ax_wlk0I1-gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature를 뽑아준다. 그러면 문장에 해당하는 feature 값들이 숫자로 쭉 나온다. 그러면 다른 문장의 숫자랑 비교할 수 있어진다."
      ],
      "metadata": {
        "id": "jxRQK9ct2E7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"fill-mask\")"
      ],
      "metadata": {
        "id": "qkAPwZsk2UFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"image-classification\")"
      ],
      "metadata": {
        "id": "G1_06zOk2lxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"image-segmentation\")"
      ],
      "metadata": {
        "id": "9jJUztsc2rC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"ner\")"
      ],
      "metadata": {
        "id": "zc1eYU5d2s9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이게 사람인지 지형인지 맞춰준다."
      ],
      "metadata": {
        "id": "otof9bKP2tpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"object-detection\")"
      ],
      "metadata": {
        "id": "unycUDft2wQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이프안에 영상 이미지 파일이 들어가는데 직사각형의 상태로 오브젝트의 구간과 오브젝트가 뭔지 알려준다."
      ],
      "metadata": {
        "id": "EybPAikH21a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"question-answering\")"
      ],
      "metadata": {
        "id": "RtB5J9bc2_pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단락이 있고 질문을 하면 답을 해준다."
      ],
      "metadata": {
        "id": "aZiP6Lax3AYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "AHaBbhWy3E5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "poditive negative 인지 알려준다. love는 positive"
      ],
      "metadata": {
        "id": "VQvxyOeY3Hc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"summarization\")"
      ],
      "metadata": {
        "id": "V6dDm9Ze3Q9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "긴 문장을 넣으면 요약해서 알혀준다."
      ],
      "metadata": {
        "id": "bZdJ1WZb3S7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "# maybe need to restart runtime\n",
        "pipe = pipeline(task=\"table-question-answering\")"
      ],
      "metadata": {
        "id": "LSvuEnV73leZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "table question answering은 pipe에 data를 넣는데 data에는 actor이름, age, 몇편의 영화에 출현했는지 엑셀의 형태로 존재한다. 우리가 자연어로 영화배우가 몇편의 영화에 출현했는지 물어보면 답을 해주는 것이 table question answering이다. 데이터가 주어져있고 질문을 하면 데이터 속에 있는 것을 내놓는다."
      ],
      "metadata": {
        "id": "SaNax01F3prG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"actors\": [\"brad pitt\", \"leonardo di caprio\", \"george clooney\"],\n",
        "    \"age\": [\"56\", \"45\", \"59\"],\n",
        "    \"number of movies\": [\"87\", \"53\", \"69\"],\n",
        "    \"date of birth\": [\"7 february 1967\", \"10 june 1996\", \"28 november 1967\"],\n",
        "}\n",
        "pipe(data, 'how old is brad pitt?')"
      ],
      "metadata": {
        "id": "caszLMCf4JMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\")"
      ],
      "metadata": {
        "id": "DVXcKXXE4N9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentimental analysis랑 비슷하다."
      ],
      "metadata": {
        "id": "DkdtK1GC4Oft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-generation\")"
      ],
      "metadata": {
        "id": "ICA2-7r84TXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "일부의 텍스트를 주면 나머지 부분을 채워준다."
      ],
      "metadata": {
        "id": "PGKsMK1Q4T9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text2text-generation\")"
      ],
      "metadata": {
        "id": "WvdFiuvq4mlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위랑 비슷"
      ],
      "metadata": {
        "id": "sYlYvsEW4o0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"token-classification\")"
      ],
      "metadata": {
        "id": "UcA3204l4spO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "token 하나하나의 단어가 뭔지. 문장을 주면 단어가 사람인지 오브젝트인지 지형인지 맞혀준다."
      ],
      "metadata": {
        "id": "VgBzNtLy4tPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"translation_en_to_de\")"
      ],
      "metadata": {
        "id": "5FmS91H642B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "번역해준다. 언어를 특정해줘야 한다. 영어 to독일어"
      ],
      "metadata": {
        "id": "za6duvcz42lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"zero-shot-classification\")"
      ],
      "metadata": {
        "id": "lrQplPRM4_ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사진을 찍고 이거는 강아지다 고양이이다라고 가르쳐준다. 하지만 여기서는 아무런 학습 없이 그냥 이게 뭔지 물어본다.   \n",
        "pipe에 어떤 문장을 준다. 그러면 이게 몇개 중에서 어떤 것과 관련된 문장인지 맞추라고 시킨다."
      ],
      "metadata": {
        "id": "CBZLfO605D7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"one day I will see the world\", ['travel', 'cooking', 'dancing'])"
      ],
      "metadata": {
        "id": "DAoCEi6y5DTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"zero-shot-image-classification\")"
      ],
      "metadata": {
        "id": "a52p0O8h5bbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "네이버나 구글렌지로 사진 찍고 어떠한 사진인지 물어본다. 이런 것은 미리 ai가 훈련되어있기에 classfication하는 건게 zero shot은 훈련이 없다. 사진을 넣고 훈련 없이 질문을 한다. 그리고 뒤에 cat인지 dog인지 물어보면 훈련 없이 답변을 한다."
      ],
      "metadata": {
        "id": "3JYS30NX5eKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "pipe(url, candidate_labels=[\"a photo of a cat\", \"a photo of a dog\"])"
      ],
      "metadata": {
        "id": "TIweWR405drI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}