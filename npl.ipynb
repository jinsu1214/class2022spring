{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN06SCAw/OZMmVufmQPx7ZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsu1214/class2022spring/blob/main/npl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFHP79bXd0v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk : natural language  \n",
        "artificial language와 반대 개념 (컴퓨터 언어와 반대인 사람의 언어를 말한다) text라고 생각하자  \n",
        "Tokenization: 긴 텍스트를 단어 수준의 단위로 끊는 것을 의미한다.  \n",
        "Normalization: 깔끔하게 하는 것, 동사에 접두사 붙고 명사에 접미사 붙는 것과 같ㅌ은 것을 정리하는 것   \n",
        "Stopword: 너무 많이 쓰는 조동사 대명사 관사 등에는 관심이 없다(the, a, is) 너무 자주 나오는 단어들은 분석에 쓸모 없기 때문에 불용어 리스트라고 한다.  \n",
        "Collocation: 연어, take care나 Michle Smith와 같은 따라 나오는 단어   \n",
        "Concordance: 단어가 나올 때 용례를 찾아주는 것  \n",
        "Frequency: 어떤 단어가 많이 사용되었는지 (pitcher는 야구에서 많이 사용)   \n",
        "Dictionary: 사전  \n",
        "pos tag: 품사의 정의와 설명, 예 등을 정리해놓은 것   \n",
        "Wordcloud: 단어의 빈도별로 글자의 크기를 달리 해서 정리한 것  \n",
        "Regular expression: 규칙을 표현하는 것, 어떤 텍스트에 서치나 조작을 하고 싶을 때 서치를 해서 찾아내는 것, 규칙들을 이용해 서치한다."
      ],
      "metadata": {
        "id": "-WXL96rCXzk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "55DGxICVaN-3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy a file from github\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/crime_punishment.txt\"\n",
        "os.system(\"curl \" + url + \" > crime_punishment.txt\")\n",
        "\n",
        "# read a text file in the server\n",
        "file = open(\"crime_punishment.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "nRFfuUxQbc-m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "metadata": {
        "id": "XtssKmzRb60x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write out a text file\n",
        "file = open(\"tmp.txt\", \"w\")\n",
        "file.write(text)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "ewePVIO-cAMc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tmt.txt하면 text를 파일화할 수 있다."
      ],
      "metadata": {
        "id": "gcXEBVAucD0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.split()"
      ],
      "metadata": {
        "id": "ERUnsA1gcTkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기를 기준으로 쪼개준다 이때 쉼표도 전 단어에 포함해야 한다."
      ],
      "metadata": {
        "id": "kCoN_i5_cVYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text.split())"
      ],
      "metadata": {
        "id": "zYtfQhvycl9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기를 기준으로 list에 있는 토큰들을 다 결합해라"
      ],
      "metadata": {
        "id": "8SXpsw3gcosh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "wdJLRqGkdBvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 실행을 해주면 쉼표나 마침표 같은 펑츄에이션도 쪼개주게 된다."
      ],
      "metadata": {
        "id": "PdJOOGrJdGvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "BtNLOXK9dQLC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이는 우리가 마침표나 쉼표 같은 것들은 필요하지 않기 때문에 없애주는 역할을 한다."
      ],
      "metadata": {
        "id": "xLK8pr0kdTtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization  \n",
        "Stemming 어간 추출 대충의 패턴 규칙으로 어미를 잘라내는 것 (사전에 없는 어간 나올 수 있음)\n",
        "Lemmatization 표제어(기본 사전형) 추출"
      ],
      "metadata": {
        "id": "x7vOW8Z0dbQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "wzZ3pvJUd508"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "hF5W06Dbd7kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "둘 다 어미를 분리해주기는 하지만 매우 부정확함"
      ],
      "metadata": {
        "id": "hTwJCcxBd8fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "metadata": {
        "id": "6DqITik9eFk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상하게 잘라놓은 것 들을 다시 원상태로 돌려줌"
      ],
      "metadata": {
        "id": "H-Sck7fpeHVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopword"
      ],
      "metadata": {
        "id": "qkwhqzVOeLE9"
      }
    }
  ]
}