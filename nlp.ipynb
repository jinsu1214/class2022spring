{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxTKqDO0ycJBl+ysUxKpsE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsu1214/class2022spring/blob/main/npl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFHP79bXd0v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk : natural language  \n",
        "artificial language와 반대 개념 (컴퓨터 언어와 반대인 사람의 언어를 말한다) text라고 생각하자  \n",
        "Tokenization: 긴 텍스트를 단어 수준의 단위로 끊는 것을 의미한다.  \n",
        "Normalization: 깔끔하게 하는 것, 동사에 접두사 붙고 명사에 접미사 붙는 것과 같ㅌ은 것을 정리하는 것   \n",
        "Stopword: 너무 많이 쓰는 조동사 대명사 관사 등에는 관심이 없다(the, a, is) 너무 자주 나오는 단어들은 분석에 쓸모 없기 때문에 불용어 리스트라고 한다.  \n",
        "Collocation: 연어, take care나 Michle Smith와 같은 따라 나오는 단어   \n",
        "Concordance: 단어가 나올 때 용례를 찾아주는 것  \n",
        "Frequency: 어떤 단어가 많이 사용되었는지 (pitcher는 야구에서 많이 사용)   \n",
        "Dictionary: 사전  \n",
        "pos tag: 품사의 정의와 설명, 예 등을 정리해놓은 것   \n",
        "Wordcloud: 단어의 빈도별로 글자의 크기를 달리 해서 정리한 것  \n",
        "Regular expression: 규칙을 표현하는 것, 어떤 텍스트에 서치나 조작을 하고 싶을 때 서치를 해서 찾아내는 것, 규칙들을 이용해 서치한다."
      ],
      "metadata": {
        "id": "-WXL96rCXzk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "55DGxICVaN-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy a file from github\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/crime_punishment.txt\"\n",
        "os.system(\"curl \" + url + \" > crime_punishment.txt\")\n",
        "\n",
        "# read a text file in the server\n",
        "file = open(\"crime_punishment.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "nRFfuUxQbc-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "metadata": {
        "id": "XtssKmzRb60x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write out a text file\n",
        "file = open(\"tmp.txt\", \"w\")\n",
        "file.write(text)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "ewePVIO-cAMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tmt.txt하면 text를 파일화할 수 있다."
      ],
      "metadata": {
        "id": "gcXEBVAucD0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.split()"
      ],
      "metadata": {
        "id": "ERUnsA1gcTkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기를 기준으로 쪼개준다 이때 쉼표도 전 단어에 포함해야 한다."
      ],
      "metadata": {
        "id": "kCoN_i5_cVYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text.split())"
      ],
      "metadata": {
        "id": "zYtfQhvycl9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기를 기준으로 list에 있는 토큰들을 다 결합해라"
      ],
      "metadata": {
        "id": "8SXpsw3gcosh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "wdJLRqGkdBvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 실행을 해주면 쉼표나 마침표 같은 펑츄에이션도 쪼개주게 된다."
      ],
      "metadata": {
        "id": "PdJOOGrJdGvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "BtNLOXK9dQLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이는 우리가 마침표나 쉼표 같은 것들은 필요하지 않기 때문에 없애주는 역할을 한다."
      ],
      "metadata": {
        "id": "xLK8pr0kdTtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization  \n",
        "Stemming 어간 추출 대충의 패턴 규칙으로 어미를 잘라내는 것 (사전에 없는 어간 나올 수 있음)\n",
        "Lemmatization 표제어(기본 사전형) 추출"
      ],
      "metadata": {
        "id": "x7vOW8Z0dbQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "wzZ3pvJUd508"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "hF5W06Dbd7kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "둘 다 어미를 분리해주기는 하지만 매우 부정확함"
      ],
      "metadata": {
        "id": "hTwJCcxBd8fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "metadata": {
        "id": "6DqITik9eFk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상하게 잘라놓은 것 들을 다시 원상태로 돌려줌"
      ],
      "metadata": {
        "id": "H-Sck7fpeHVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopword"
      ],
      "metadata": {
        "id": "qkwhqzVOeLE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)"
      ],
      "metadata": {
        "id": "ZfTpJBrB2hXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "둘이 비교해보면 s나 to등이 빠져있는 것을 확인할 수 있다."
      ],
      "metadata": {
        "id": "1mVjwE4I2lYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocation, Concordance  \n",
        "gutenberg는 기간이 지나 저작권이 없는 글들을 모아둔 것, 성경도 포함  \n",
        "text는 str로 들어가 있고 words는 retokenize했기 때문에 list로 들어가 있다."
      ],
      "metadata": {
        "id": "SsCAg-Cz3J96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "A6a_ZxT13Y3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "collocation은 연속해서 나오는 두개의 단어   \n",
        "원래 뒤에 num이랑 window_size해줘야 하는데 안 하면 고정값으로 나온다.   \n",
        "num은 20개 찾으라는 것이고 window_size는 연속해서 나오는 단어의 갯수를 말한다. 3은 세개의 단어가 연속으로 나오는것을 의미"
      ],
      "metadata": {
        "id": "Tb24u4vw4S2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).collocations()  # default: (num=20, window_size=2)"
      ],
      "metadata": {
        "id": "iCayoELJ4o1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "concordance는 용례이다.\n",
        "Emma라는 단어가 등장하는 앞 뒤 context를 10개 찾아라  \n",
        "79는 그 단어가 들어간 문장을 찾는데 앞뒤로 79글자만 뽑아서 보여달라는 것을 의미"
      ],
      "metadata": {
        "id": "2hfUCTBb45JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ],
      "metadata": {
        "id": "C0I-bfZ04rn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dispersion plot   \n",
        "words에 들어가 있는 160000개의 단어들 중에서 이 단어가 나오는 곳은 어디인지 표로 보여주는 것  누가 주인공이고 조연인지 알 수 있다."
      ],
      "metadata": {
        "id": "QXz6wDIf52qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ],
      "metadata": {
        "id": "yR1KA5HN6ZoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "similar는 분포 상으로 유사한 것이 무엇인가를 말한다.  \n",
        "Emma와 비슷하게 나온 것이 무엇인지 찾아라.  \n",
        "이렇게 하면 she나 it등과 같은 자주 나오는 단어들이 나온다."
      ],
      "metadata": {
        "id": "cyizyfg46h5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distributional similarity: \n",
        "# find other words which appear in the same contexts as the specified word; \n",
        "# list most similar words first.\n",
        "nltk.Text(words).similar(\"Emma\")"
      ],
      "metadata": {
        "id": "qDb1fvFi61h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "common context  \n",
        "이렇게 하면 단어 두개사이에_가 끼인 상태로 등장하는데 이 _ 사이에 Emma나 She 가 등장할 확률이 높다는 것을 의미"
      ],
      "metadata": {
        "id": "eUnZ1pLe62hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find contexts where the specified words appear; list most frequent common contexts first.\n",
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ],
      "metadata": {
        "id": "o8CuVEGX7JkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency distribution, Frequency plot"
      ],
      "metadata": {
        "id": "xvgdJAPn7KSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ],
      "metadata": {
        "id": "ASDhMgDg7Pex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 해주면 특정 단어가 몇번 등장하는지 알려준다.   \n",
        "위의 것이랑 똑같은 것을 그래프로도 표현이 가능하다."
      ],
      "metadata": {
        "id": "phKWVrLW7RyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).plot(20)"
      ],
      "metadata": {
        "id": "9IGskwmF7cwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary  \n",
        "여기서 들어간 en은 english를 의미한다."
      ],
      "metadata": {
        "id": "8CwrSsQb7d1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]"
      ],
      "metadata": {
        "id": "hp7isEkP7xdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pos tag는 part of speech라 해서 품사이다.  \n",
        "접속사, 관사, 형용사, 대명사, 소유격, 동사 등이 있다."
      ],
      "metadata": {
        "id": "eLK8EW8yeTW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
        "words = nltk.word_tokenize(sent)"
      ],
      "metadata": {
        "id": "jNi6SzGLemjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 tokenize를 해줘야 한다."
      ],
      "metadata": {
        "id": "CAHD4VE_eoVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ],
      "metadata": {
        "id": "14A4ESdmesd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos"
      ],
      "metadata": {
        "id": "89wRGDPQeubm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ],
      "metadata": {
        "id": "1tGTHRJqe3nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NE"
      ],
      "metadata": {
        "id": "7rCeGz_jfEBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 오류가 있지만 교수님도 모르신다...."
      ],
      "metadata": {
        "id": "LyO48kILfFXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Worldcloud\n",
        "freauency랑 관련 있고 글자 폰트를 다르게 해준다."
      ],
      "metadata": {
        "id": "T59UYGDLfK1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
        "\n",
        "wc = WordCloud().generate(text) \n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "0IcrKlrUfZJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래 stopword는 nltk에서 다 정해져 있지만 우리가 추가할 수도 있다.  \n",
        "add unto 해서 unto를 추가할 수 있다."
      ],
      "metadata": {
        "id": "0lDpCijzfibj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(STOPWORDS) \n",
        "stopwords.add('unto')\n",
        "wc = WordCloud(stopwords = stopwords).generate(text) \n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "7GY6IPKOf0N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expression   \n",
        "re.search는 왼쪽에 있는 str 사이에서 오른쪽을 찾으라는 이야기. 두개가 있더라도 제일 처음 발견되는 것만 발견한다."
      ],
      "metadata": {
        "id": "UeOeWASbtT7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.search('a', 'abcdefa')"
      ],
      "metadata": {
        "id": "Bj9jAWeZt4gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re.findall 은 전부 다 찾아주는 것이다. 다 찾아서 list로 만들어준다."
      ],
      "metadata": {
        "id": "vUYHL1wLt_us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('a', 'abcdefa')"
      ],
      "metadata": {
        "id": "dAoiyAQmuTAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re.sub는 replace한다는 것이다. a를 b로 바꾸어라"
      ],
      "metadata": {
        "id": "4TZpoFXtuTnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub('a', 'b', 'abcdefa')"
      ],
      "metadata": {
        "id": "C73ZLRdjue-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engdict = nltk.corpus.words.words('en')"
      ],
      "metadata": {
        "id": "kCldy6NKwtu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사전은 list형태로 존재하고 있다. 하지만 search나 findall은 string일 때 작동한다. 따라서 engdict[10]이런식으로 가져와서 string 상태로 사용할 것이다."
      ],
      "metadata": {
        "id": "ZS_lO-c7w2wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ah]+$', w)]\n",
        "print(result[:10])"
      ],
      "metadata": {
        "id": "Pw0vDSkixpMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a를 찾아라도 아니라 이상한게 들어가 있다. 규칙이 들어가 있는 것이다.   \n",
        "위의 if절에서 뱉어지는 것은 ed이다. 단어 전체가 나오는 것은 아니다.   \n",
        "만약 w가 아니라 educated이면 ed가 처음에도 있고 뒤에도 있지만 $가 있기 때문에 뒤의 ed만 가져올 것이다. 만약 아무것도 없이 그냥 ed만 찾으라 한다면 가장 먼저 만나는 ed를 가져올 것이다. ^ed이면 앞의 ed를 가져올 것이다.   \n",
        "하지만 이것은 if절을 통과하냐 마느냐의 문제이고 for문법까지 거친다면 ed가 들어가는 전체 단어가 결과로 나올 것이다."
      ],
      "metadata": {
        "id": "uhXZjk0Eph9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "^jt$하면 이것은 j로 시작하고 t로 끝나는 것이기에 그냥 jt이다. 따라서 아무런 것도 나오지 않는다.  만약 우리가 ^..j..t..$를 해주면 . 개수에 맞게 아무런 단어가 들어가는 단어를 찾아낸다."
      ],
      "metadata": {
        "id": "AmAMbp3HsFrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 대괄호가 있는데 이는 대괄호 속에 들어가 있는 단어 중에서 하나를 만족시키면 된다. 즉 첫번째 단어는 g, h, i중에 하나 두번째 단어는 m, n , o 중에 하나를 가져와야 한다."
      ],
      "metadata": {
        "id": "w_Z_bAjKsugQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 +가 있다. 만약 a+가 있으면 a가 한번이상 있어야 한다는 것을 의미한다. 여기에서는 a혹은 h가 한번 이상 나와야 한다는 것을 의미한다."
      ],
      "metadata": {
        "id": "R05yML6NtIfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\\d\n",
        "Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "\\D\n",
        "Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "\\s\n",
        "Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
        "\\S\n",
        "Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
        "\\w\n",
        "Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "\\W\n",
        "Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "pkpQesxJp-HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()"
      ],
      "metadata": {
        "id": "RO8rfo-Rtq3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이것은 신문에 있는 모든 단어들을 담은 것이다. 사전보다 더 현실적이고 10만 달러와 같은 단어도 들어있을 것이다."
      ],
      "metadata": {
        "id": "Et0aBV6ytvK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        "\n",
        "result = sorted(set(result))\n",
        "print(result[:10])"
      ],
      "metadata": {
        "id": "Ai_q7134t6lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째는 괄호가 되어 있고 가운데 ㅣ 가 있다. ed 혹은 ing로 끝나는 단어를 찾으라는 것이다.   \n",
        "sorted는 단어들이 abc순서대로 나오게 해준다."
      ],
      "metadata": {
        "id": "HUYi393XuDeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[0-9] 는 숫자를 뜻한다. 즉 숫자가 하나 이상 나오면서 시작한다는 것을 의미한다. 점을 표현할 때 마침표는 any character를 말하기 때문에 역/가 점 역할을 한다. 그리고 뒤에는 소수점을 의미하게 된다. 0.0085, 0,05, 0,2~ 가 결과값으로 나온다."
      ],
      "metadata": {
        "id": "eJ9DXbmzu9b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 역/$가 실제 $로 쓰인다는 것을 주의하면 된다. 그냥 $가 나오면 string의 끝을 의마한다."
      ],
      "metadata": {
        "id": "j_1Pg_Vbv5r9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "{4}가 의미하는 것은 {} 앞에 있는 것이 4번 반복한다는 것을 의미한다. 따라서 4자리 숫자를 의미하는 것이다."
      ],
      "metadata": {
        "id": "pNS10j3CwV4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 는 그냥 - 이다. {3,5}은 3개이상 5개 이하를 의미한다."
      ],
      "metadata": {
        "id": "tMCkZA3twmGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "{5, }는 5개 이상을 의미하고 { ,6}은 6개 이하를 의미한다."
      ],
      "metadata": {
        "id": "L8Eyqr2dw1Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '(?<=: ).+(?=[\\.|\\?|\\!])'\n",
        "sent = re.findall(pattern, text)\n",
        "sent\n",
        "text = '\\n'.join(sent)"
      ],
      "metadata": {
        "id": "E_p107v4xwA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(?<=a).(?=b)왼쪽에 a가 있고 오른쪽에 b가 있는데 중간에 있는 캐릭터 하나를 달라는 의미    \n",
        "(?<=: ).+ (?=[역/.ㅣ역/?ㅣ역/!])"
      ],
      "metadata": {
        "id": "YUcsg23ZyAzt"
      }
    }
  ]
}
